{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGqBhnEYCnFb",
        "toc": true
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cleaning-Data\" data-toc-modified-id=\"Cleaning-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cleaning Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Null-values\" data-toc-modified-id=\"Null-values-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Null values</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cleaning-Null-Values\" data-toc-modified-id=\"Cleaning-Null-Values-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Cleaning Null Values</a></span></li><li><span><a href=\"#Checking-for-Null-Values\" data-toc-modified-id=\"Checking-for-Null-Values-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Checking for Null Values</a></span></li><li><span><a href=\"#Dropping-Null-Values\" data-toc-modified-id=\"Dropping-Null-Values-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Dropping Null Values</a></span></li><li><span><a href=\"#Filling-Null-Values\" data-toc-modified-id=\"Filling-Null-Values-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Filling Null Values</a></span></li><li><span><a href=\"#ðŸ’¡-Check-for-understanding\" data-toc-modified-id=\"ðŸ’¡-Check-for-understanding-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>ðŸ’¡ Check for understanding</a></span></li></ul></li><li><span><a href=\"#Dealing-with-Duplicates\" data-toc-modified-id=\"Dealing-with-Duplicates-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Dealing with Duplicates</a></span><ul class=\"toc-item\"><li><span><a href=\"#Identifying-Duplicates\" data-toc-modified-id=\"Identifying-Duplicates-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Identifying Duplicates</a></span></li><li><span><a href=\"#Removing-Duplicates\" data-toc-modified-id=\"Removing-Duplicates-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Removing Duplicates</a></span></li><li><span><a href=\"#Removing-Duplicates-Based-on-Specific-Columns\" data-toc-modified-id=\"Removing-Duplicates-Based-on-Specific-Columns-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Removing Duplicates Based on Specific Columns</a></span></li><li><span><a href=\"#Resetting-the-Index\" data-toc-modified-id=\"Resetting-the-Index-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Resetting the Index</a></span></li></ul></li><li><span><a href=\"#Formatting-Data\" data-toc-modified-id=\"Formatting-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Formatting Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Formatting-Numeric-Values\" data-toc-modified-id=\"Formatting-Numeric-Values-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Formatting Numeric Values</a></span></li><li><span><a href=\"#Formatting-Strings\" data-toc-modified-id=\"Formatting-Strings-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Formatting Strings</a></span></li><li><span><a href=\"#Formatting-Dates\" data-toc-modified-id=\"Formatting-Dates-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Formatting Dates</a></span></li></ul></li><li><span><a href=\"#Cleaning-Column-Names\" data-toc-modified-id=\"Cleaning-Column-Names-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Cleaning Column Names</a></span></li></ul></li><li><span><a href=\"#Using-apply(),-map(),-and-applymap()\" data-toc-modified-id=\"Using-apply(),-map(),-and-applymap()-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Using <code>apply()</code>, <code>map()</code>, and <code>applymap()</code></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Apply()\" data-toc-modified-id=\"Apply()-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span><code>Apply()</code></a></span></li><li><span><a href=\"#Map()\" data-toc-modified-id=\"Map()-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span><code>Map()</code></a></span></li><li><span><a href=\"#applyMap()\" data-toc-modified-id=\"applyMap()-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span><code>applyMap()</code></a></span></li><li><span><a href=\"#More-examples\" data-toc-modified-id=\"More-examples-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>More examples</a></span><ul class=\"toc-item\"><li><span><a href=\"#Comparing-Map-and-Apply\" data-toc-modified-id=\"Comparing-Map-and-Apply-2.0.4.1\"><span class=\"toc-item-num\">2.0.4.1&nbsp;&nbsp;</span>Comparing Map and Apply</a></span></li><li><span><a href=\"#Calculating-the-length-of-the-name\" data-toc-modified-id=\"Calculating-the-length-of-the-name-2.0.4.2\"><span class=\"toc-item-num\">2.0.4.2&nbsp;&nbsp;</span>Calculating the length of the name</a></span></li><li><span><a href=\"#Converting-to-float-some-columns-with-applymap()\" data-toc-modified-id=\"Converting-to-float-some-columns-with-applymap()-2.0.4.3\"><span class=\"toc-item-num\">2.0.4.3&nbsp;&nbsp;</span>Converting to float some columns with applymap()</a></span></li><li><span><a href=\"#Modifying-cloumns-names-with-apply()\" data-toc-modified-id=\"Modifying-cloumns-names-with-apply()-2.0.4.4\"><span class=\"toc-item-num\">2.0.4.4&nbsp;&nbsp;</span>Modifying cloumns names with apply()</a></span></li></ul></li><li><span><a href=\"#ðŸ’¡-Check-for-understanding\" data-toc-modified-id=\"ðŸ’¡-Check-for-understanding-2.0.5\"><span class=\"toc-item-num\">2.0.5&nbsp;&nbsp;</span>ðŸ’¡ Check for understanding</a></span></li><li><span><a href=\"#ðŸ’¡-Check-for-understanding\" data-toc-modified-id=\"ðŸ’¡-Check-for-understanding-2.0.6\"><span class=\"toc-item-num\">2.0.6&nbsp;&nbsp;</span>ðŸ’¡ Check for understanding</a></span></li></ul></li></ul></li><li><span><a href=\"#Filtering-Data\" data-toc-modified-id=\"Filtering-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Filtering Data</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-condition\" data-toc-modified-id=\"Creating-a-condition-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Creating a condition</a></span></li><li><span><a href=\"#Filtering-df\" data-toc-modified-id=\"Filtering-df-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Filtering df</a></span></li><li><span><a href=\"#Using-multiple-conditions\" data-toc-modified-id=\"Using-multiple-conditions-3.0.3\"><span class=\"toc-item-num\">3.0.3&nbsp;&nbsp;</span>Using multiple conditions</a></span></li></ul></li></ul></li><li><span><a href=\"#More-Data-Manipulation\" data-toc-modified-id=\"More-Data-Manipulation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>More Data Manipulation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setting-the-index\" data-toc-modified-id=\"Setting-the-index-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Setting the index</a></span></li><li><span><a href=\"#Adding/removing-rows-and/or-columns\" data-toc-modified-id=\"Adding/removing-rows-and/or-columns-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Adding/removing rows and/or columns</a></span></li><li><span><a href=\"#ðŸ’¡-Check-for-understanding\" data-toc-modified-id=\"ðŸ’¡-Check-for-understanding-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>ðŸ’¡ Check for understanding</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioL4qYxaCnFi",
        "tags": []
      },
      "source": [
        "# Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz7aV8e9CnFj"
      },
      "source": [
        "## Null values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vjLBgJACnFj"
      },
      "source": [
        "Null values (also known as missing values) are common in datasets and can hinder data analysis and modeling. It is essential to handle null values appropriately to ensure accurate and reliable results. Pandas provides various methods to clean and handle null values in datasets.\n",
        "\n",
        "In Python, `None` is a special constant that represents the absence of a value. It is commonly used to indicate that a variable or function has no value or hasn't been assigned any value. For example, if a function does not explicitly return a value, it implicitly returns `None`.\n",
        "\n",
        "On the other hand, `NaN` stands for \"Not a Number\" and is a special value used to represent missing or undefined numerical data. `NaN` is part of the floating-point representation and is commonly used in numeric data structures like Pandas DataFrames and Series to indicate missing or invalid numerical values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZVn3rnCCnFj"
      },
      "source": [
        "\n",
        "\n",
        "### Cleaning Null Values\n",
        "\n",
        "1. Checking for Null Values:\n",
        "   - Use `isnull()` method to check for null values in a DataFrame or Series.\n",
        "   - Use `notnull()` method to check for non-null values in a DataFrame or Series.\n",
        "\n",
        "2. Dropping Null Values:\n",
        "   - Use `dropna()` method to remove rows with null values from a DataFrame.\n",
        "   - Use `dropna(axis=1)` to remove columns with null values.\n",
        "\n",
        "3. Filling Null Values:\n",
        "   - Use `fillna(value)` method to replace null values with a specific value.\n",
        "   - Use `fillna(method='ffill')` to forward-fill null values with the previous non-null value.\n",
        "   - Use `fillna(method='bfill')` to backward-fill null values with the next non-null value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPKEhg5aCnFj"
      },
      "source": [
        "### Checking for Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LqjVuWlkCnFj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Titanic dataset from an online source\n",
        "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/titanic_train.csv'\n",
        "df= pd.read_csv(url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8HjY_ZZCnFk"
      },
      "source": [
        "When working with large datasets, using `isna()` or `isnull()` along with `any()` and `sum()` in Pandas becomes essential for quick and efficient data quality assessment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9SmMfg6NCnFk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG6ZmrBVCnFk"
      },
      "source": [
        "sum() calculates the sum of each row, considering True as 1 and False as 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8ktKBrP1CnFk"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
              "      <td>female</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PP 9549</td>\n",
              "      <td>16.7000</td>\n",
              "      <td>G6</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bonnell, Miss. Elizabeth</td>\n",
              "      <td>female</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113783</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>C103</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>872</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11751</td>\n",
              "      <td>52.5542</td>\n",
              "      <td>D35</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>873</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Carlsson, Mr. Frans Olof</td>\n",
              "      <td>male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>695</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>B51 B53 B55</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>880</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
              "      <td>female</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11767</td>\n",
              "      <td>83.1583</td>\n",
              "      <td>C50</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>183 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "1              2         1       1   \n",
              "3              4         1       1   \n",
              "6              7         0       1   \n",
              "10            11         1       3   \n",
              "11            12         1       1   \n",
              "..           ...       ...     ...   \n",
              "871          872         1       1   \n",
              "872          873         0       1   \n",
              "879          880         1       1   \n",
              "887          888         1       1   \n",
              "889          890         1       1   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
              "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
              "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
              "..                                                 ...     ...   ...    ...   \n",
              "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
              "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
              "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
              "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
              "\n",
              "     Parch    Ticket     Fare        Cabin Embarked  \n",
              "1        0  PC 17599  71.2833          C85        C  \n",
              "3        0    113803  53.1000         C123        S  \n",
              "6        0     17463  51.8625          E46        S  \n",
              "10       1   PP 9549  16.7000           G6        S  \n",
              "11       0    113783  26.5500         C103        S  \n",
              "..     ...       ...      ...          ...      ...  \n",
              "871      1     11751  52.5542          D35        S  \n",
              "872      0       695   5.0000  B51 B53 B55        S  \n",
              "879      1     11767  83.1583          C50        C  \n",
              "887      0    112053  30.0000          B42        S  \n",
              "889      0    111369  30.0000         C148        C  \n",
              "\n",
              "[183 rows x 12 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sd=df.dropna(axis=1)\n",
        "sd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4xsvxUbCnFk"
      },
      "source": [
        "If we add the parameter `axis=1` with the `sum()` function, we can calculate the sum of each row (along the columns) of the DataFrame `df`. This results in a Series that contains the count of null values in each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ytT0UjZpCnFk",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58UdOIKQCnFk"
      },
      "source": [
        "### Dropping Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFwax3J5CnFk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZSKOoH9CnFk"
      },
      "source": [
        "However, as we can see below in the DataFrame, the rows with NaN values have not been removed. To execute the change, it is necessary to use the `inplace=True` option: `df.dropna(inplace=True)` or assign it to a variable such as df = df.dropna()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCYfJnETCnFl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ9Hq-AQCnFl"
      },
      "source": [
        "In the `dropna()` method of Pandas DataFrame, the `subset`, `how`, and `thresh` parameters are used to control the behavior of dropping rows or columns containing NaN (null) values, when we don't want to drop them just because they have *one* null value:\n",
        "\n",
        "- `subset`: It allows you to specify a subset of columns on which to apply the `dropna()` operation. Only the rows containing NaN values in the specified subset of columns will be dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbhWzPAmCnFl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zNFOr2qCnFl"
      },
      "source": [
        "- `how`: It specifies the condition for dropping rows. It can take the values 'any', which means to drop rows containing any NaN values in the `subset`, or 'all', which means to drop rows containing all NaN values in the `subset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEb3JcEcCnFl",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8oyNUapCnFl"
      },
      "source": [
        "- `thresh`: It sets a minimum threshold for the number of non-null values that a row must have in the `subset` in order to be kept. Rows with fewer non-null values than the specified threshold will be dropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOz2ftkaCnFl",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcM36B3YCnFl"
      },
      "source": [
        "### Filling Null Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1AoyfsqCnFl"
      },
      "source": [
        "`fillna()` is a Pandas method used to replace NaN (null) values in a DataFrame or Series with specified values.\n",
        "- You can use `inplace=True` to modify the DataFrame directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii3bX0R2CnFl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MXBPxBOCnFm"
      },
      "source": [
        "Careful if we assign a different data type, since Pandas will change the data type of the whole column. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp490ltNCnFm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRlDc2uUCnFm"
      },
      "source": [
        "To avoid this, we can select manually in which column to apply the `fillna()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uTvGbIYCnFm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Qf6TyeCnFm"
      },
      "source": [
        "We can also use the mean(), median() etc. to fill the null values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qz-LeDO3CnFm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8sazPSlCnFm"
      },
      "source": [
        "- Two common methods for filling NaN values are `ffill`, which forward fills using the last valid value, and `bfill`, which backward fills using the next valid value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9iGVMC_CnFm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E45QKUddCnFm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IBvGKHOCnFm"
      },
      "source": [
        "### ðŸ’¡ Check for understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXV-zvVeCnFm"
      },
      "source": [
        "Consider the following DataFrame containing information about students:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Cathy', None, 'Eva'],\n",
        "    'Age': [25, 30, None, 22, 28],\n",
        "    'Gender': ['Female', None, 'Female', 'Male', None],\n",
        "    'Score': [90, None, 78, None, 85]\n",
        "}\n",
        "\n",
        "df_students = pd.DataFrame(data)\n",
        "```\n",
        "\n",
        "Your task is to perform the following data cleaning tasks:\n",
        "\n",
        "1. Check for null values in the DataFrame using `isna()` or `isnull()`.\n",
        "\n",
        "2. Replace the null values in the 'Age' column with the average age of the students.\n",
        "\n",
        "3. Replace the null values in the 'Gender' column with \"Female\".\n",
        "\n",
        "4. Drop any rows that have null values in the 'Name' column.\n",
        "\n",
        "5. Forward fill (ffill) the null values in the 'Score' column with the previous valid value.\n",
        "\n",
        "6. After performing all the cleaning steps, print the cleaned DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32RWpVM3CnFm"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQuimxxHCnFm"
      },
      "source": [
        "## Dealing with Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNO-MV7oCnFm"
      },
      "source": [
        "In data analysis, it's common to encounter duplicate values in datasets. Duplicates can distort our analysis and lead to incorrect conclusions. Fortunately, pandas provides efficient methods to handle duplicates.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoklfHUPCnFm"
      },
      "source": [
        "### Identifying Duplicates\n",
        "\n",
        "To identify duplicate rows in a DataFrame, we can use the `duplicated()` method, which returns a boolean Series indicating whether each row is a duplicate or not. We can then use the `sum()` method to count the total number of duplicates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QQa4lKwCnFm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AriiG9BWCnFm"
      },
      "source": [
        "To check for duplicates in specific columns, we can use the `duplicated()` method with the `subset` parameter, or just access first to the column and then check with duplicated().\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjsS5YvUCnFn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duEie7BWCnFn"
      },
      "source": [
        "### Removing Duplicates\n",
        "\n",
        "To remove duplicates from a DataFrame, we can use the `drop_duplicates()` method. By default, this method keeps the first occurrence of each duplicated row and removes the rest.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO4crWttCnFn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXuHZocACnFn"
      },
      "source": [
        "### Removing Duplicates Based on Specific Columns\n",
        "\n",
        "Sometimes, we may want to remove duplicates based on specific columns. We can pass a subset of column names to the `drop_duplicates()` method to achieve this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KY_kN0JUCnFn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAI4qDbkCnFn"
      },
      "source": [
        "By default, `drop_duplicates()` keeps the first occurrence of each duplicated row. If we want to keep the last occurrence instead, we can set the `keep` parameter to `'last'`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke90ERAZCnFn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5_Rq7K4CnFn"
      },
      "source": [
        "### Resetting the Index\n",
        "\n",
        "When removing duplicates, the DataFrame index may have gaps due to removed rows. To reset the index after removing duplicates, we can use the `reset_index()` method with the `drop=True` parameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWyQE6QmCnFn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47RNvr1oCnFn"
      },
      "source": [
        "## Formatting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wySkx2BzCnFn"
      },
      "source": [
        "### Formatting Numeric Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbeVX4rbCnFn"
      },
      "source": [
        "\n",
        "1. `round()` Method:\n",
        "   - Rounds numeric values to a specified number of decimal places.\n",
        "\n",
        "2. `format()` Method:\n",
        "   - Formats numeric values as strings for better representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvMeXWPUCnFn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pksit9zCnFn"
      },
      "source": [
        "### Formatting Strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQTsR2bCCnFn"
      },
      "source": [
        "Check the data structures lesson for more string operations and formatting. Here we'll just look at some of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycnKst6nCnFn"
      },
      "source": [
        "1. **Using f-strings (formatted string literals):**\n",
        "   - f-strings are introduced in Python 3.6 and provide a concise and readable way to format strings.\n",
        "   - Place variables or expressions inside curly braces `{}` in the string, preceded by the `f` character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ID5AkkCnFo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwCh85leCnFo"
      },
      "source": [
        "2. **Using the `format()` method:**\n",
        "   - The `format()` method can be applied to a string and accepts positional or keyword arguments to replace placeholders.\n",
        "   - Placeholders are represented by curly braces `{}` and can be indexed or named."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svFVyYtaCnFo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28IchMDKCnFo"
      },
      "source": [
        "3. **Using `%` formatting:**\n",
        "   - `%` formatting is an older method, similar to C-style formatting, but less recommended due to its limitations and lack of flexibility.\n",
        "   - Placeholders are represented by `%` followed by format specifiers, like `%s` for strings and `%d` for integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KIqR0QoCnFo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiMrwCIcCnFo"
      },
      "source": [
        "Let's look at some methods for formatting strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxtvFGH3CnFo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "graExqxhCnFo"
      },
      "source": [
        "### Formatting Dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aelVutGQCnFo"
      },
      "source": [
        "We will study this in another Notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EpuHyJ1CnFo",
        "tags": []
      },
      "source": [
        "## Cleaning Column Names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKs75zMdCnFp"
      },
      "source": [
        "We can acccess the columns using `df.columns`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwMlk5YgCnFp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4H2drqaCnFp"
      },
      "source": [
        "In order to modify them, we can assign new column names to `df.columns` by doing `df.columns = [list_of_new_column_names]` or we can use the `rename()` method to just modify a few of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL5m6gkdCnFp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF2uPoO3CnFp"
      },
      "source": [
        "# Using `apply()`, `map()`, and `applymap()`\n",
        "\n",
        "- `apply()`\n",
        "    - Apply a custom function to a Series.\n",
        "    - Useful for element-wise transformations.\n",
        "    - Example: `df['squared_numbers'] = df['numbers'].apply(lambda x: x ** 2)`\n",
        "\n",
        "- `map()`\n",
        "    - Transform Series elements based on a dictionary.\n",
        "    - Replaces elements with corresponding dictionary values.\n",
        "    - Example: `df['gender_mapped'] = df['gender'].map({'M': 'Male', 'F': 'Female'})`\n",
        "\n",
        "- `applymap()`\n",
        "    - Apply a custom function to every element in a DataFrame.\n",
        "    - Useful for element-wise transformations on entire DataFrames.\n",
        "    - Example: `df = df.applymap(lambda x: x.upper())`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9GCXyQaCnFp"
      },
      "source": [
        "###Â `Apply()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x9Mnsf2CnFp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tufnyCEhCnFp"
      },
      "source": [
        "In the example above, we can see that to create a new column in pandas, we can simply assign a new Series or list to a new column name within the DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUxYAKSmCnFp"
      },
      "source": [
        "To edit the information in a whole column in pandas, you can simply assign a new list or array of values to the column you want to modify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fLDoQY8CnFp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkeub6iaCnFp"
      },
      "source": [
        "###Â `Map()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUVTS-heCnFp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gnL2Ka1CnFp"
      },
      "source": [
        "###Â `applyMap()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8253U25CnFp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lkf3RKHCnFp"
      },
      "source": [
        "### More examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHL5Ki98CnFp"
      },
      "source": [
        "#### Comparing Map and Apply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwY5emsPCnFp"
      },
      "source": [
        "We have a column called \"Embarked\" containing three possible values: 'C', 'Q', and 'S'. We want to map these values to 0, 1 and 2. In this case, `apply()` with a lambda function would be complex due to the if-elif-else conditions, but `map()` can handle it more easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGmgHLZrCnFp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMrgpWpHCnFq"
      },
      "source": [
        "Why is it a float?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQO0E7FOCnFq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu6NEc-RCnFq"
      },
      "source": [
        "#### Calculating the length of the name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-r611CZCnFq"
      },
      "source": [
        "What if we wanted to create a new column with the length of the name?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIKc7f_mCnFq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAqckF6YCnFq"
      },
      "source": [
        "#### Converting to float some columns with applymap()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBb3GcyuCnFq"
      },
      "source": [
        "Lets look just as an example, how to make float all the following columns: \"PassengerId\", \"Survived\", \"Pclass\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ks9Jf8NCnFq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUROZFl4CnFq"
      },
      "source": [
        "#### Modifying cloumns names with apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6V41iZbCnFq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzZBwbEoCnFq"
      },
      "source": [
        "### ðŸ’¡ Check for understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMbk_maaCnFq"
      },
      "source": [
        "Make the column Embarked_nr as an integer type.\n",
        "\n",
        "- If you get an error, read the error, and think how you should proceed.\n",
        "- If you decide to fill the null values, use the mode() since its a categorical variable.\n",
        "- If you get another error, look at what mode() is returning in order to fix the error and convert to integer the Embarked_nr column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn8afKqBCnFq"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOUIhm7LCnFq"
      },
      "source": [
        "### ðŸ’¡ Check for understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldS8GVVaCnFr"
      },
      "source": [
        "You are given a dataset of students' exam scores here: https://raw.githubusercontent.com/data-bootcamp-v4/data/main/student_performance.csv. Your task is to perform the following operations using pandas:\n",
        "\n",
        "1. Read the CSV file into a DataFrame.\n",
        "2. Create a new column \"total_score\" that calculates the total score for each student by summing their \"math score,\" \"reading score,\" and \"writing score.\"\n",
        "3. Create a new column \"grade\" that assigns a grade to each student based on the following criteria:\n",
        "   - If the total score is >= 90, the grade is \"A.\"\n",
        "   - If the total score is >= 80 and < 90, the grade is \"B.\"\n",
        "   - If the total score is >= 70 and < 80, the grade is \"C.\"\n",
        "   - If the total score is >= 60 and < 70, the grade is \"D.\"\n",
        "   - If the total score is < 60, the grade is \"F.\"\n",
        "4. Convert all student names in the \"gender\" column to uppercase.\n",
        "5. Create a new column \"is_passed\" that indicates whether each student has passed the exam or not. If the total score is >= 60, the student has passed; otherwise, they have failed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZpmJUsiCnFr"
      },
      "outputs": [],
      "source": [
        "df_students = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/student_performance.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bYrGx24CnFr"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnxMI1KsCnFr",
        "tags": []
      },
      "source": [
        "# Filtering Data\n",
        "\n",
        "One of the primary tasks in dataset analysis is filtering rows.\n",
        "\n",
        "When filtering DataFrames in Pandas, you can use boolean indexing to select specific rows based on certain conditions. Here's a step-by-step explanation:\n",
        "\n",
        "1. Identify the column(s) you want to use as a filter condition. For example, in `housing_df` the column named 'SalePrice'.\n",
        "\n",
        "2. Create a condition using a comparison operator (e.g., `>`, `<`, `==`, etc.) and the column(s) you want to filter. For instance, to filter all rows where the 'SalePrice' is greater than 10000, you would use `condition = housing_df['SalePrice'] > 10000`.\n",
        "\n",
        "3. Use the condition to filter the DataFrame. You can do this by passing the condition inside square brackets to the DataFrame. For example, `filtered_df = housing_df[condition]` will create a new DataFrame `filtered_df` containing only the rows where the 'SalePrice' is greater than 10000.\n",
        "\n",
        "Keep in mind that the condition should evaluate to a boolean Series with the same length as the DataFrame, indicating which rows to include (True) or exclude (False).\n",
        "\n",
        "You can also combine multiple conditions using logical operators like `&` for 'and' and `|` for 'or'. For instance, to filter rows where the 'SalePrice' is greater than 10000 and the 'FullBath' is more than 1, you can use `condition = (housing_df['SalePrice'] > 10000) & (housing_df['FullBath'] > 1)`.\n",
        "\n",
        "Filtering allows you to extract specific subsets of data from your DataFrame, making it easier to analyze and work with the data that meets your criteria.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS14iulsCnFr"
      },
      "source": [
        "### Creating a condition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DHeFIQECnFr",
        "tags": []
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAnQ3klmCnFr"
      },
      "source": [
        "### Filtering df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhDy-Y4jCnFr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWPewrwnCnFr"
      },
      "source": [
        "### Using multiple conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CasuVoTNCnFr",
        "tags": []
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q-icRs4CnFr"
      },
      "source": [
        "# More Data Manipulation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA6YIRl-CnFr"
      },
      "source": [
        "## Setting the index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OILJaZOxCnFr"
      },
      "source": [
        "To set an index in pandas, you can use the `set_index()` method of the DataFrame. This method allows you to specify which column you want to use as the index for the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUeSgS3kCnFs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IutbZIs2CnFs"
      },
      "source": [
        "## Adding/removing rows and/or columns\n",
        "\n",
        "To add or remove rows and/or columns from a pandas DataFrame, you can use the following methods:\n",
        "\n",
        "1. Adding rows:\n",
        "   - Use the `append()` method to add rows to the DataFrame.\n",
        "\n",
        "2. Removing rows:\n",
        "   - Use the `drop()` method with the row index or label to remove specific rows.\n",
        "\n",
        "3. Adding columns:\n",
        "   - Using `df[new_column]`, you simply assign a list, Series, or scalar value to the new column name\n",
        "   - Assign a new column to the DataFrame using bracket notation or the `assign()` method.\n",
        "\n",
        "4. Removing columns:\n",
        "   - Use the `drop()` method with the column name and `axis=1` to remove specific columns.\n",
        "   - Alternatively, you can use the `del` keyword to remove a column in-place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYoeacZRCnFs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q1kDslTCnFs"
      },
      "source": [
        "## ðŸ’¡ Check for understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNTCsvq-CnFs"
      },
      "source": [
        "Use the `supermarket_sales.csv` file for this task.\n",
        "\n",
        "1. **Load the Data**: Use pandas to load the `supermarket_sales.csv` file into a DataFrame.\n",
        "\n",
        "2. **Null Values**: Check if the DataFrame has any null values. If there are any, count the number of null values in each column.\n",
        "\n",
        "5. **Formatting Data**: Round any floating point numbers in the DataFrame to two decimal places.\n",
        "\n",
        "6. **Cleaning Column Names**: Ensure all column names are in lowercase and replace any spaces in the column names with underscores.\n",
        "\n",
        "7. **Using apply(), map(), and applymap()**: Create a new column called 'total_cost' which is the product of the 'quantity' and 'unit_price' columns (assuming these columns exist in your dataset). Use the `apply()` function for this.\n",
        "\n",
        "8. **Filtering Data**: Filter the DataFrame to only include rows where 'total_cost' is greater than the average 'total_cost'.\n",
        "\n",
        "9. **Setting the Index**: Set the 'invoice_id' column (or any other unique identifier) as the index of the DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U5-dGiXCnFs"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/supermarket_sales.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdDnqYTiCnFs"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yM4bideCnFs"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmDQy2p3CnFs"
      },
      "source": [
        "1. Null Values:\n",
        "   - Null values (also known as missing values) can hinder data analysis and modeling.\n",
        "   - Use `isnull()` or `isna()` to check for null values in a DataFrame or Series.\n",
        "   - Use `any()` and `sum()` to efficiently assess data quality.\n",
        "   - Use `dropna()` to remove rows or columns with null values from a DataFrame.\n",
        "   - Parameters like subset, how, and thresh can control the behavior of dropping rows or columns.\n",
        "   - Use `fillna()` to replace null values with specific values, such as `mean()`, `median()`, or forward/backward fill.\n",
        "\n",
        "5. Formatting Data:\n",
        "   - Use `round()` and `format()` to format numeric values.\n",
        "   - Use f-strings, `format()` or % to format strings and use string methods like `lower()`, `upper()`, `title()`, `strip()`, `split()`, and `replace()`.\n",
        "\n",
        "6. Cleaning Column Names:\n",
        "   - Use df.columns to access column names.\n",
        "   - Modify column names using df.columns or `rename()`.\n",
        "\n",
        "7. Using `apply()`, `map()`, and `applymap()`:\n",
        "   - `apply()`: Applies a custom function to a Series.\n",
        "   - `map()`: Transforms Series elements based on a dictionary.\n",
        "   - `applymap()`: Applies a custom function to every element in a DataFrame.\n",
        "\n",
        "8. Filtering Data:\n",
        "   - Filter rows in a DataFrame using boolean indexing.\n",
        "   - Use comparison operators (<, >, ==) to create conditions.\n",
        "   - Combine multiple conditions using logical operators (& for 'and', | for 'or').\n",
        "\n",
        "9. Setting the Index:\n",
        "   - Use `set_index()` to set an index for the DataFrame.\n",
        "\n",
        "10. Adding/Removing Rows and Columns:\n",
        "   - Use `append()` to add rows to the DataFrame.\n",
        "   - Use `drop()` with the row index/label to remove specific rows.\n",
        "   - Use bracket notation, `assign()`, or `drop()` with axis=1 to add/remove columns."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "537.273px",
        "left": "27.9957px",
        "top": "110.824px",
        "width": "260px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
